# typed: strong

module Anthropic
  module Models
    class Message < Anthropic::BaseModel
      # Unique object identifier.
      #
      #   The format and length of IDs may change over time.
      sig { returns(String) }
      def id
      end

      sig { params(_: String).returns(String) }
      def id=(_)
      end

      # Content generated by the model.
      #
      #   This is an array of content blocks, each of which has a `type` that determines
      #   its shape.
      #
      #   Example:
      #
      #   ```json
      #   [{ "type": "text", "text": "Hi, I'm Claude." }]
      #   ```
      #
      #   If the request input `messages` ended with an `assistant` turn, then the
      #   response `content` will continue directly from that last turn. You can use this
      #   to constrain the model's output.
      #
      #   For example, if the input `messages` were:
      #
      #   ```json
      #   [
      #     {
      #       "role": "user",
      #       "content": "What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun"
      #     },
      #     { "role": "assistant", "content": "The best answer is (" }
      #   ]
      #   ```
      #
      #   Then the response `content` might be:
      #
      #   ```json
      #   [{ "type": "text", "text": "B)" }]
      #   ```
      sig do
        returns(
          T::Array[
          T.any(
            Anthropic::Models::TextBlock,
            Anthropic::Models::ToolUseBlock,
            Anthropic::Models::ThinkingBlock,
            Anthropic::Models::RedactedThinkingBlock
          )
          ]
        )
      end
      def content
      end

      sig do
        params(
          _: T::Array[
          T.any(
            Anthropic::Models::TextBlock,
            Anthropic::Models::ToolUseBlock,
            Anthropic::Models::ThinkingBlock,
            Anthropic::Models::RedactedThinkingBlock
          )
          ]
        )
          .returns(
            T::Array[
            T.any(
              Anthropic::Models::TextBlock,
              Anthropic::Models::ToolUseBlock,
              Anthropic::Models::ThinkingBlock,
              Anthropic::Models::RedactedThinkingBlock
            )
            ]
          )
      end
      def content=(_)
      end

      # The model that will complete your prompt.\n\nSee
      #   [models](https://docs.anthropic.com/en/docs/models-overview) for additional
      #   details and options.
      sig { returns(T.any(Symbol, String)) }
      def model
      end

      sig { params(_: T.any(Symbol, String)).returns(T.any(Symbol, String)) }
      def model=(_)
      end

      # Conversational role of the generated message.
      #
      #   This will always be `"assistant"`.
      sig { returns(Symbol) }
      def role
      end

      sig { params(_: Symbol).returns(Symbol) }
      def role=(_)
      end

      # The reason that we stopped.
      #
      #   This may be one the following values:
      #
      #   - `"end_turn"`: the model reached a natural stopping point
      #   - `"max_tokens"`: we exceeded the requested `max_tokens` or the model's maximum
      #   - `"stop_sequence"`: one of your provided custom `stop_sequences` was generated
      #   - `"tool_use"`: the model invoked one or more tools
      #
      #   In non-streaming mode this value is always non-null. In streaming mode, it is
      #   null in the `message_start` event and non-null otherwise.
      sig { returns(T.nilable(Symbol)) }
      def stop_reason
      end

      sig { params(_: T.nilable(Symbol)).returns(T.nilable(Symbol)) }
      def stop_reason=(_)
      end

      # Which custom stop sequence was generated, if any.
      #
      #   This value will be a non-null string if one of your custom stop sequences was
      #   generated.
      sig { returns(T.nilable(String)) }
      def stop_sequence
      end

      sig { params(_: T.nilable(String)).returns(T.nilable(String)) }
      def stop_sequence=(_)
      end

      # Object type.
      #
      #   For Messages, this is always `"message"`.
      sig { returns(Symbol) }
      def type
      end

      sig { params(_: Symbol).returns(Symbol) }
      def type=(_)
      end

      # Billing and rate-limit usage.
      #
      #   Anthropic's API bills and rate-limits by token counts, as tokens represent the
      #   underlying cost to our systems.
      #
      #   Under the hood, the API transforms requests into a format suitable for the
      #   model. The model's output then goes through a parsing stage before becoming an
      #   API response. As a result, the token counts in `usage` will not match one-to-one
      #   with the exact visible content of an API request or response.
      #
      #   For example, `output_tokens` will be non-zero, even for an empty string response
      #   from Claude.
      #
      #   Total input tokens in a request is the summation of `input_tokens`,
      #   `cache_creation_input_tokens`, and `cache_read_input_tokens`.
      sig { returns(Anthropic::Models::Usage) }
      def usage
      end

      sig { params(_: Anthropic::Models::Usage).returns(Anthropic::Models::Usage) }
      def usage=(_)
      end

      sig do
        params(
          id: String,
          content: T::Array[
          T.any(
            Anthropic::Models::TextBlock,
            Anthropic::Models::ToolUseBlock,
            Anthropic::Models::ThinkingBlock,
            Anthropic::Models::RedactedThinkingBlock
          )
          ],
          model: T.any(Symbol, String),
          stop_reason: T.nilable(Symbol),
          stop_sequence: T.nilable(String),
          usage: Anthropic::Models::Usage,
          role: Symbol,
          type: Symbol
        )
          .returns(T.attached_class)
      end
      def self.new(id:, content:, model:, stop_reason:, stop_sequence:, usage:, role: :assistant, type: :message)
      end

      sig do
        override
          .returns(
            {
              id: String,
              content: T::Array[
              T.any(
                Anthropic::Models::TextBlock,
                Anthropic::Models::ToolUseBlock,
                Anthropic::Models::ThinkingBlock,
                Anthropic::Models::RedactedThinkingBlock
              )
              ],
              model: T.any(Symbol, String),
              role: Symbol,
              stop_reason: T.nilable(Symbol),
              stop_sequence: T.nilable(String),
              type: Symbol,
              usage: Anthropic::Models::Usage
            }
          )
      end
      def to_hash
      end

      # The reason that we stopped.
      #
      #   This may be one the following values:
      #
      #   - `"end_turn"`: the model reached a natural stopping point
      #   - `"max_tokens"`: we exceeded the requested `max_tokens` or the model's maximum
      #   - `"stop_sequence"`: one of your provided custom `stop_sequences` was generated
      #   - `"tool_use"`: the model invoked one or more tools
      #
      #   In non-streaming mode this value is always non-null. In streaming mode, it is
      #   null in the `message_start` event and non-null otherwise.
      class StopReason < Anthropic::Enum
        abstract!

        END_TURN = T.let(:end_turn, T.nilable(Symbol))
        MAX_TOKENS = T.let(:max_tokens, T.nilable(Symbol))
        STOP_SEQUENCE = T.let(:stop_sequence, T.nilable(Symbol))
        TOOL_USE = T.let(:tool_use, T.nilable(Symbol))

        class << self
          sig { override.returns(T::Array[Symbol]) }
          def values
          end
        end
      end
    end
  end
end
